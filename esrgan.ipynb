{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [],
      "dockerImageVersionId": 30823,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "esrgan",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bansaldolly527-lab/deeplearningproj/blob/main/esrgan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-29T10:38:45.70466Z",
          "iopub.execute_input": "2024-12-29T10:38:45.705064Z",
          "iopub.status.idle": "2024-12-29T10:38:45.710271Z",
          "shell.execute_reply.started": "2024-12-29T10:38:45.705032Z",
          "shell.execute_reply": "2024-12-29T10:38:45.708811Z"
        },
        "id": "-4IqGa197GSK"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](attachment:bcc81a09-bdd0-4e6b-beb1-8e708bfc604f.png)\n",
        "\n"
      ],
      "metadata": {
        "id": "eE_-pOaf7GSP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Conv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, use_activation= True ):\n",
        "        super().__init__()\n",
        "        self.conv1= nn.Conv2d(in_channels, out_channels, kernel_size= kernel_size, stride=stride , padding=padding)\n",
        "        self.activation= nn.LeakyReLU(inplace=True) if use_activation else nn.Identity()\n",
        "\n",
        "    def forward(self,x):\n",
        "        x=self.conv1(x)\n",
        "        x=self.activation(x)\n",
        "        return x"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-28T13:06:26.56978Z",
          "iopub.execute_input": "2024-12-28T13:06:26.570137Z",
          "iopub.status.idle": "2024-12-28T13:06:26.576235Z",
          "shell.execute_reply.started": "2024-12-28T13:06:26.570109Z",
          "shell.execute_reply": "2024-12-28T13:06:26.574979Z"
        },
        "id": "0C3ovq7p7GSV"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class DenseBlock(nn.Module):\n",
        "    def __init__(self, in_channels, channels=64, beta=0.2):\n",
        "        super().__init__()\n",
        "        blocks=[]\n",
        "        for i in range(5):\n",
        "            blocks.append(Conv(in_channels=in_channels+channels*i,\n",
        "                               out_channels=channels if i <4 else in_channels  ,\n",
        "                               kernel_size=3,\n",
        "                               stride=1,\n",
        "                               padding=1,\n",
        "                              use_activation= True if i<4 else False\n",
        "                              ))\n",
        "\n",
        "        self.conv_layers=nn.Sequential(*blocks)\n",
        "        self.beta= beta\n",
        "\n",
        "    def forward(self, x):\n",
        "        inputs = x\n",
        "        for layer in self.conv_layers:\n",
        "            out = layer(inputs)\n",
        "            inputs = torch.cat([inputs, out], dim=1) # last concat is unnecessary\n",
        "        return out * self.beta + x                   # scale the outputs of the dense block\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        ""
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-28T13:11:21.315526Z",
          "iopub.execute_input": "2024-12-28T13:11:21.315989Z",
          "iopub.status.idle": "2024-12-28T13:11:21.324384Z",
          "shell.execute_reply.started": "2024-12-28T13:11:21.315951Z",
          "shell.execute_reply": "2024-12-28T13:11:21.322916Z"
        },
        "id": "rK_lMcZB7GSX"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class RRDB(nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "        super().__init__()\n",
        "        blocks=[]\n",
        "        for i in range(3):\n",
        "            blocks.append(DenseBlock(in_channels))\n",
        "\n",
        "        self.layers=nn.Sequential(*blocks)\n",
        "\n",
        "    def forward(self, x):\n",
        "        inputs=x\n",
        "        for layer in self.layers:\n",
        "            x=layer(x)\n",
        "        return 0.2*x+inputs"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-28T13:11:26.064681Z",
          "iopub.execute_input": "2024-12-28T13:11:26.065111Z",
          "iopub.status.idle": "2024-12-28T13:11:26.128982Z",
          "shell.execute_reply.started": "2024-12-28T13:11:26.065076Z",
          "shell.execute_reply": "2024-12-28T13:11:26.127799Z"
        },
        "id": "cgV7ix_j7GSa",
        "outputId": "c299c1dc-763f-4ebf-db95-2234fc72d8d9"
      },
      "outputs": [
        {
          "execution_count": 17,
          "output_type": "execute_result",
          "data": {
            "text/plain": "tensor([[[[0.4554, 0.9994, 0.4231,  ..., 1.1095, 0.1548, 1.0674],\n          [0.7988, 0.5274, 0.3004,  ..., 0.8801, 0.8844, 0.1626],\n          [0.5289, 0.6769, 0.1701,  ..., 0.6001, 0.8835, 0.2978],\n          ...,\n          [0.1087, 0.3849, 0.5856,  ..., 0.6478, 0.4746, 0.9044],\n          [0.7340, 0.5345, 0.6894,  ..., 0.5598, 1.0363, 1.0023],\n          [0.4683, 0.5732, 0.8683,  ..., 1.0621, 0.0164, 0.2339]],\n\n         [[1.0692, 0.8053, 0.0503,  ..., 0.1192, 0.7475, 0.0942],\n          [0.1851, 1.1323, 0.9045,  ..., 0.2940, 1.1735, 0.4155],\n          [0.8681, 0.3606, 1.1128,  ..., 0.1313, 0.8321, 0.2090],\n          ...,\n          [1.1821, 0.2077, 0.4883,  ..., 1.0299, 0.4221, 0.5283],\n          [0.3568, 0.3638, 0.1070,  ..., 0.7025, 0.1931, 0.8730],\n          [0.0996, 0.9771, 0.1487,  ..., 0.0621, 1.1503, 0.6464]],\n\n         [[0.8035, 0.8663, 0.3375,  ..., 1.0179, 0.0452, 1.1124],\n          [0.6998, 0.2042, 0.3232,  ..., 0.1930, 0.2389, 0.6999],\n          [1.0749, 0.9602, 1.0164,  ..., 0.1188, 0.6938, 0.2022],\n          ...,\n          [0.8971, 0.9457, 0.9739,  ..., 0.4518, 1.0774, 0.8284],\n          [0.5335, 0.1321, 1.1181,  ..., 1.0085, 0.2474, 1.1626],\n          [0.0841, 0.9987, 0.9798,  ..., 1.1920, 0.6239, 0.0982]]]],\n       grad_fn=<AddBackward0>)"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "x= torch.rand(1,3,28,28)\n",
        "x\n",
        "rrdb=RRDB(3)\n",
        "rrdb(x).shape"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-28T13:34:07.509663Z",
          "iopub.execute_input": "2024-12-28T13:34:07.510122Z",
          "iopub.status.idle": "2024-12-28T13:34:07.550987Z",
          "shell.execute_reply.started": "2024-12-28T13:34:07.510088Z",
          "shell.execute_reply": "2024-12-28T13:34:07.549962Z"
        },
        "id": "EEVgg-LY7GSd",
        "outputId": "161f5201-58ca-4569-cef6-ea3f2777dd44"
      },
      "outputs": [
        {
          "execution_count": 25,
          "output_type": "execute_result",
          "data": {
            "text/plain": "torch.Size([1, 3, 28, 28])"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class Upsample(nn.Module):\n",
        "    def __init__(self, in_channels, scale_factor):\n",
        "        super().__init__()\n",
        "        self.conv1= nn.Conv2d(in_channels=in_channels, out_channels=in_channels, kernel_size=3, padding=1, stride=1)\n",
        "        self.upsample = nn.Upsample(scale_factor=scale_factor, mode='bilinear', align_corners=False)\n",
        "        self.activation= nn.LeakyReLU(0.2, inplace=True)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x=self.upsample(x)\n",
        "        x=self.conv1(x)\n",
        "        x=self.activation(x)\n",
        "        return x\n",
        "ups=Upsample(3,200)\n",
        "out=ups(x)\n",
        "out.shape"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-28T13:21:17.818288Z",
          "iopub.execute_input": "2024-12-28T13:21:17.818633Z",
          "iopub.status.idle": "2024-12-28T13:21:19.608578Z",
          "shell.execute_reply.started": "2024-12-28T13:21:17.818607Z",
          "shell.execute_reply": "2024-12-28T13:21:19.60738Z"
        },
        "id": "3Zl45uFM7GSg",
        "outputId": "5f49e977-11fb-4433-91f3-6244bd21e7ef"
      },
      "outputs": [
        {
          "execution_count": 24,
          "output_type": "execute_result",
          "data": {
            "text/plain": "torch.Size([1, 3, 5600, 5600])"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, in_channels, channels=64, scale_factor=2):\n",
        "        super().__init__()\n",
        "        self.conv1=nn.Conv2d(in_channels, channels, kernel_size=3, padding=1, stride=1 )\n",
        "        blocks=[]\n",
        "        for i in range(23):\n",
        "            blocks.append(RRDB(channels))\n",
        "        self.rrdb=nn.Sequential(*blocks)\n",
        "        self.conv2=Conv(channels, channels, kernel_size=3, stride=1 , padding=1 )\n",
        "        self.upsample=Upsample(channels, scale_factor)\n",
        "        self.conv3=Conv(channels, channels, kernel_size=3, padding=1, stride=1)\n",
        "        self.conv4=Conv(channels, in_channels, kernel_size=3, padding=1, stride=1, use_activation=False)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x=self.conv1(x)\n",
        "        residual=x\n",
        "        x=self.rrdb(x)\n",
        "        x=self.conv2(x)\n",
        "        x=x+residual\n",
        "        x=self.upsample(x)\n",
        "        x=self.upsample(x)\n",
        "        x=self.conv3(x)\n",
        "        x=self.conv4(x)\n",
        "        return x\n",
        "gen=Generator(3)\n",
        "otp=gen(x)\n",
        "otp.shape"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-28T13:54:00.13662Z",
          "iopub.execute_input": "2024-12-28T13:54:00.137173Z",
          "iopub.status.idle": "2024-12-28T13:54:01.520622Z",
          "shell.execute_reply.started": "2024-12-28T13:54:00.137133Z",
          "shell.execute_reply": "2024-12-28T13:54:01.519532Z"
        },
        "id": "3ZKgkIVR7GSi",
        "outputId": "41334508-566c-4986-a5ac-9dffbfcc1d6d"
      },
      "outputs": [
        {
          "execution_count": 30,
          "output_type": "execute_result",
          "data": {
            "text/plain": "torch.Size([1, 3, 112, 112])"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#discrimator\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, in_channels=3, features=[64, 64, 128, 128, 256, 256, 512, 512])\n",
        "        super().__init__()\n",
        "        blocks=[]\n",
        "        for idx, feature in enumerate(features):\n",
        "            blocks.append(Conv(in_channels, feature, kernel_size=3, stride=1+idx%2, padding=1, use_activation=True))\n",
        "            in_channels=feature\n",
        "        self.blocks=nn.Sequential(*blocks)\n",
        "        self.classifier= nn.Sequential(\n",
        "            nn.AdaptiveAvgPoool2d((6,6)),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(512*6*6,1024)\n",
        "            nn.LeakyReLU(0.2, inplace=True)\n",
        "            nn.Linear(1024,1)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        x=self.blocks(x)\n",
        "        return self.classifier(x)\n",
        ""
      ],
      "metadata": {
        "trusted": true,
        "id": "NTQGXMt17GSk"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_weights(model, scale=0.1)\n",
        "    for m in model.module():\n",
        "        if isinstance(m, nn.Conv2d):\n",
        "            nn.init.kaiming_normal_(m.weight.data)\n",
        "            m.weight.data *= scale\n",
        "\n",
        "        elif isinstance(m, nn.Linear):\n",
        "            nn.init.kaiming_normal_(m.weight.data)\n",
        "            m.weight.data *= scale\n",
        ""
      ],
      "metadata": {
        "trusted": true,
        "id": "UjlE0NRG7GSo"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def test():\n",
        "    gen=Generator(3)\n",
        "    disc=Discriminator()\n",
        "    low_res=24\n",
        "    x=torch.randn((5, 3, low_res))\n",
        "    gen_out= gen(x)\n",
        "    disc_out=disc(gen_out)\n",
        "\n",
        "    print(gen_out.shape)\n",
        "    print(disc_out.shape)\n",
        "test()"
      ],
      "metadata": {
        "trusted": true,
        "id": "OIbr3hLW7GSq"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models import vgg19\n",
        "# import config\n",
        "\n",
        "class VGGLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.vgg=vgg19(pretrained=True).features[:35].eval()\n",
        "\n",
        "\n",
        "        for param in self.vgg.parameters():\n",
        "            param.requires_grad=False\n",
        "        self.loss=nn.MSELoss()\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        vgg_input_features=self.vgg(input)\n",
        "        vgg_target_features= self.vgg(target)\n",
        "        return self.loss(vgg_input_features, vgg_target_features)\n",
        ""
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-29T10:38:55.489653Z",
          "iopub.execute_input": "2024-12-29T10:38:55.490022Z",
          "iopub.status.idle": "2024-12-29T10:38:55.496609Z",
          "shell.execute_reply.started": "2024-12-29T10:38:55.48999Z",
          "shell.execute_reply": "2024-12-29T10:38:55.495417Z"
        },
        "id": "P6O4S7Xd7GSs"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import config\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from utils import gradient_penalty, load_checkpoint, save_checkpoint, plot_examples\n",
        "from loss import VGGLoss\n",
        "from torch.utils.data import DataLoader\n",
        "from model import Generator, Discriminator, initialize_weights\n",
        "from tqdm import tqdm\n",
        "from dataset import MyImageFolder\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "def train_fn(loader, disc, gen, opt_gen, opt_disc, l1, vgg_loss, g_scaler, d_scaler, writer, tb_step,):\n",
        "    loop = tqdm(loader, leave=True)\n",
        "\n",
        "    for idx, (low_res, high_res) in enumerate(loop):\n",
        "        high_res = high_res.to(config.DEVICE)\n",
        "        low_res = low_res.to(config.DEVICE)\n",
        "\n",
        "        with torch.cuda.amp.autocast():\n",
        "            fake = gen(low_res)\n",
        "            critic_real = disc(high_res)\n",
        "            critic_fake = disc(fake.detach())\n",
        "            gp = gradient_penalty(disc, high_res, fake, device=config.DEVICE)\n",
        "            loss_critic = (-(torch.mean(critic_real) - torch.mean(critic_fake))+ config.LAMBDA_GP )\n",
        "\n",
        "        opt_disc.zero_grad()\n",
        "        d_scaler.scale(loss_critic).backward()\n",
        "        d_scaler.step(opt_disc)\n",
        "\n",
        "        d_scaler.update()\n",
        "\n",
        "        # Train Generator: min log(1 - D(G(z))) <-> max log(D(G(z))\n",
        "        with torch.cuda.amp.autocast():\n",
        "            l1_loss = 1e-2 * l1(fake, high_res)\n",
        "            adversarial_loss = 5e-3 * -torch.mean(disc(fake))\n",
        "            loss_for_vgg = vgg_loss(fake, high_res)\n",
        "            gen_loss = l1_loss + loss_for_vgg + adversarial_loss\n",
        "\n",
        "        opt_gen.zero_grad()\n",
        "        g_scaler.scale(gen_loss).backward()\n",
        "        g_scaler.step(opt_gen)\n",
        "        g_scaler.update()\n",
        "\n",
        "        writer.add_scalar(\"Critic loss\", loss_critic.item(), global_step=tb_step)\n",
        "        tb_step += 1\n",
        "\n",
        "        if idx % 100 == 0 and idx > 0:\n",
        "            plot_examples(\"test_images/\", gen)\n",
        "\n",
        "        loop.set_postfix(gp=gp.item(),critic=loss_critic.item(),l1=l1_loss.item(),vgg=loss_for_vgg.item(),adversarial=adversarial_loss.item(),)\n",
        "\n",
        "    return tb_step\n",
        "\n",
        "\n",
        "def main():\n",
        "    dataset = MyImageFolder(root_dir=\"data/\")\n",
        "    loader = DataLoader(\n",
        "        dataset,\n",
        "        batch_size=config.BATCH_SIZE,\n",
        "        shuffle=True,\n",
        "        pin_memory=True,\n",
        "        num_workers=config.NUM_WORKERS,\n",
        "    )\n",
        "    gen = Generator(in_channels=3).to(config.DEVICE)\n",
        "    disc = Discriminator(in_channels=3).to(config.DEVICE)\n",
        "    initialize_weights(gen)\n",
        "    opt_gen = optim.Adam(gen.parameters(), lr=config.LEARNING_RATE, betas=(0.0, 0.9))\n",
        "    opt_disc = optim.Adam(disc.parameters(), lr=config.LEARNING_RATE, betas=(0.0, 0.9))\n",
        "    writer = SummaryWriter(\"logs\")\n",
        "    tb_step = 0\n",
        "    l1 = nn.L1Loss()\n",
        "    gen.train()\n",
        "    disc.train()\n",
        "    vgg_loss = VGGLoss()\n",
        "\n",
        "    g_scaler = torch.cuda.amp.GradScaler()\n",
        "    d_scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "    if config.LOAD_MODEL:\n",
        "        load_checkpoint(\n",
        "            config.CHECKPOINT_GEN,\n",
        "            gen,\n",
        "            opt_gen,\n",
        "            config.LEARNING_RATE,\n",
        "        )\n",
        "        load_checkpoint(\n",
        "            config.CHECKPOINT_DISC,\n",
        "            disc,\n",
        "            opt_disc,\n",
        "            config.LEARNING_RATE,\n",
        "        )\n",
        "\n",
        "\n",
        "    for epoch in range(config.NUM_EPOCHS):\n",
        "        tb_step = train_fn(loader,disc,gen,opt_gen,opt_disc,l1,vgg_loss,g_scaler,d_scaler,writer,tb_step,)\n",
        "\n",
        "        if config.SAVE_MODEL:\n",
        "            save_checkpoint(gen, opt_gen, filename=config.CHECKPOINT_GEN)\n",
        "            save_checkpoint(disc, opt_disc, filename=config.CHECKPOINT_DISC)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    try_model = True\n",
        "\n",
        "    if try_model:\n",
        "        # Will just use pretrained weights and run on images\n",
        "        # in test_images/ and save the ones to SR in saved/\n",
        "        gen = Generator(in_channels=3).to(config.DEVICE)\n",
        "        opt_gen = optim.Adam(gen.parameters(), lr=config.LEARNING_RATE, betas=(0.0, 0.9))\n",
        "        load_checkpoint(\n",
        "            config.CHECKPOINT_GEN,\n",
        "            gen,\n",
        "            opt_gen,\n",
        "            config.LEARNING_RATE,\n",
        "        )\n",
        "        plot_examples(\"test_images/\", gen)\n",
        "    else:\n",
        "        # This will train from scratch\n",
        "        main()"
      ],
      "metadata": {
        "trusted": true,
        "id": "driVjgi37GSt"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}